{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\17020\\miniconda3\\envs\\proto\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1 导入包\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP_Model(\n",
      "  (layer1): Sequential(\n",
      "    (0): Linear(in_features=104, out_features=50, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=23, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 2 创建model\n",
    "class BP_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BP_Model,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(nn.Linear(104,50),nn.Sigmoid())\n",
    "        self.layer2 = nn.Sequential(nn.Linear(50,23))\n",
    "\n",
    "    def forward(self,flow):\n",
    "        flow = self.layer1(flow)\n",
    "        flow = self.layer2(flow)\n",
    "        return flow\n",
    " \n",
    "# 创建和实例化一个整个模型类的对象\n",
    "model = BP_Model()\n",
    "# 打印出整个模型\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinghan\\AppData\\Local\\Temp\\ipykernel_84804\\955486019.py:4: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_set = pd.read_csv(\"test_set.csv\",header=None) .values\n"
     ]
    }
   ],
   "source": [
    "# 3 读取数据集\n",
    "# dataframe = pd.read_csv(\"total.csv\",header=None).values # 取消第一行作为表头\n",
    "# train_set = pd.read_csv(\"train_set.csv\",header=None).values\n",
    "test_set = pd.read_csv(\"test_set.csv\",header=None) .values\n",
    "\n",
    "# train_set = np.array(train_set[1:,:]).astype(np.float32) # 去掉第一行字段 \n",
    "test_set = np.array(test_set[1:,:]).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 4 读标签\n",
    "# label = dataframe.loc[:,['label']]\n",
    "# train_label = train_set[:,0]\n",
    "test_label = test_set[:,0]\n",
    "\n",
    "\n",
    "# 5 读特征\n",
    "# train_feature  = train_set[:,1:]\n",
    "test_feature = test_set[:,1:]\n",
    "\n",
    "\n",
    "print(type(test_feature))\n",
    "\n",
    "# 转换成tensor (台式没有GPU 就不转换了)\n",
    "# train_feature_tensor = torch.tensor(train_feature)\n",
    "test_feature_tensor = torch.tensor(test_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0017, 0.0017, 0.0017,  ..., 0.0017, 0.0017, 0.0017])\n",
      "(340208, 104)\n"
     ]
    }
   ],
   "source": [
    "# 6 对特征进行归一化\n",
    "test_nor = torch.nn.functional.normalize(test_feature_tensor,dim=0,eps=1e-12, out=None)\n",
    "\n",
    "\n",
    "print(test_nor[:,1])\n",
    "\n",
    "print(test_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch不会隐式地调整输入的形状。因此，\n",
    "# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状\n",
    "net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)\n",
    "\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 定义损失函数和优化器\n",
    "\n",
    "loss = nn.CrossEntropyLoss(reduction='none') # 损失函数\n",
    "optimizer = torch.optim.SGD(model.parameters(),1e-1) # 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.1) # 学习率为0.1的小批量随机梯度下降作为优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(test_set, batch_size=64, shuffle=True)  # 训练数据\n",
    "test_data = DataLoader(test_set, batch_size=128, shuffle=False)  # 测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 开始训练\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "train_acces = []\n",
    "# 用数组保存每一轮迭代中，在测试数据上测试的损失值和精确度，也是为了通过画图展示出来。\n",
    "eval_losses = []\n",
    "eval_acces = []\n",
    "\n",
    "for e in test_feature_tensor:\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()   # 将模型改为训练模式\n",
    "    # 4.1==========================训练模式==========================\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()   # 将模型改为训练模式\n",
    "\n",
    "    # 每次迭代都是处理一个小批量的数据，batch_size是64\n",
    "    for im, label in train_data:\n",
    "        im = Variable(im)\n",
    "        label = Variable(label)\n",
    "\n",
    "        # 计算前向传播，并且得到损失函数的值\n",
    "        out = model(im)\n",
    "        loss = criterion(out, label)\n",
    "\n",
    "        # 反向传播，记得要把上一次的梯度清0，反向传播，并且step更新相应的参数。\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 记录误差\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # 计算分类的准确率\n",
    "        _, pred = out.max(1)\n",
    "        num_correct = (pred == label).sum().item()\n",
    "        acc = num_correct / im.shape[0]\n",
    "        train_acc += acc\n",
    "\n",
    "    train_losses.append(train_loss / len(train_data))\n",
    "    train_acces.append(train_acc / len(train_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "700df16ff072ff231e9563d413cf5000e57326d5383e3a689aad73bd99106d0a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('proto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
