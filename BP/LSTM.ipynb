{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 导入包\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding, SimpleRNN, Bidirectional\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape (1508190, 23)\n"
     ]
    }
   ],
   "source": [
    "# 2 读取数据集\n",
    "\n",
    "# dataframe = pd.read_csv(\"total.csv\",header=None).values # 取消第一行作为表头\n",
    "train_set = pd.read_csv(\"software_train_set.csv\")\n",
    "test_set = pd.read_csv(\"software_test_set.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# 3 读标签\n",
    "# label = dataframe.loc[:,['label']]\n",
    "y_train = train_set['label']\n",
    "y_test = test_set['label']\n",
    "\n",
    "# 标签转化为one-hot编码 \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=23)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=23)\n",
    "\n",
    "print(\"y_train.shape\",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "########## 一般是转为浮点数向量\n",
    "\n",
    "# train_set = np.array(train_set[1:,:]).astype(np.float32) # 去掉第一行字段 \n",
    "# test_set = np.array(test_set[1:,:]).astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读数据\n",
    "train_data = train_set.iloc[:,1:]\n",
    "test_data = test_set.iloc[:,1:]\n",
    "\n",
    "\n",
    "# 5 特征归一化  用MLP的时候用，LSTM不用，用embedding层 ,但是这里有2列数值太大了，\n",
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(0, 65535))\n",
    "\n",
    "train_data[['tcp.options.timestamp.tsval','tcp.options.timestamp.tsecr']] = min_max_scaler.fit_transform(train_data[['tcp.options.timestamp.tsval','tcp.options.timestamp.tsecr']])\n",
    "test_data[['tcp.options.timestamp.tsval','tcp.options.timestamp.tsecr']] = min_max_scaler.fit_transform(test_data[['tcp.options.timestamp.tsval','tcp.options.timestamp.tsecr']])\n",
    "\n",
    "train_data = train_data.values\n",
    "test_data = test_data.values\n",
    "\n",
    "train_set_GA = np.array(train_data).astype(np.int64) # 转为整数向量\n",
    "test_set_GA = np.array(test_data).astype(np.int64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集生成器\n",
    "# train_label_ = np.insert(y_train, 0, 0, axis=0)\n",
    "# test_label_ = np.insert(y_test, 0, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用TimesereisGenerator生成序列数据\n",
    "time_steps = 1\n",
    "batch_size = 1024\n",
    "\n",
    "train_generator = TimeseriesGenerator(train_set_GA, y_train, length=time_steps, sampling_rate=1, batch_size=batch_size)\n",
    "test_generator = TimeseriesGenerator(test_set_GA, y_test, length=time_steps, sampling_rate=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 74  60   1 ...   0  18   0]\n",
      " [ 58  44   0 ...   0   2   0]\n",
      " [ 54  40   1 ...   0   0   0]\n",
      " ...\n",
      " [260 246   1 ...   0  10   3]\n",
      " [ 74  60   0 ...   0  17   0]\n",
      " [ 74  60   1 ...   0  18   0]]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########## Embedding 层输入整数向量\n",
    "\n",
    "# train_set = np.array(train_set).astype(np.int32) # 转成整数\n",
    "# x_test_set = np.array(x_test_set).astype(np.int32)\n",
    "\n",
    "\n",
    "print(train_set_GA)\n",
    "print(type(test_set_GA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          2097152   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 23)                1495      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,115,287\n",
      "Trainable params: 2,115,287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(None, None, 32)\n",
      "Epoch 1/5\n",
      " 3860/21858 [====>.........................] - ETA: 3:22 - loss: 1.3350 - acc: 0.5302"
     ]
    }
   ],
   "source": [
    "##################  LSTM\n",
    "max_features = 65536  # 作为特征的(单词)索引个数\n",
    "# x_train = x_train[:, None]\n",
    "model = Sequential()\n",
    "# model.add(Dense(64, activation='relu', input_dim=104))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# keras.layers.embeddings.Embedding(input_dim, output_dim, \n",
    "#                                   init='uniform', input_length=None, W_regularizer=None, activity_regularizer=None, W_constraint=None, mask_zero=False, weights=None, dropout=0.0)\n",
    "model.add(Embedding(max_features, 32)) # 接收二维整数向量，输出三维向量\n",
    "# print(model.layers[0].get_weights()[0].shape)\n",
    "\n",
    "# exit()\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(LSTM(32)) # 接收三维向量\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(23, activation='softmax')) \n",
    "print(model.summary())\n",
    "\n",
    "print(model.get_layer(index=0).output_shape)\n",
    "# loss = [binary_crossentropy,categorical_crossentropy]\n",
    "# optimizer = [rmsprop,] RMSProp对比Adamgrad增加了指数平滑\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "model.fit(train_set_GA, y_train , epochs=5, batch_size=69, validation_data=[test_set_GA, y_test], validation_freq=1)\n",
    "# score = model.evaluate(test_set_GA, y_test, batch_size=128)\n",
    "\n",
    "#################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, epochs=250, verbose=2, steps_per_epoch=25,\n",
    "                                validation_data=test_generator, shuffle=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Embedding1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score = model.evaluate(test_set_GA, y_test, batch_size=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
