{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling1D,Conv1D,UpSampling1D\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_CNNmodel(train_data, test_data):\n",
    "\n",
    "    fnum1 = 16  ## filter1数目\n",
    "    fnum2 = 1  ## filter2数目，如果最后一层是多卷积核，那么将出现多个平行降维数据，我们可以取其中一个，或者均值，或者直接设定一个卷积核\n",
    "    ps1 = 25  ## pool_size1##这里的pooling要注意，因为存在整数运算逻辑，如果我们一维数据维度大小为1024，那么1024/25/10非正整数，将报错\n",
    "    ps2 = 10  # #pool_size2##如果是2050，则降维后一维数据维度为2500/25/10=10\n",
    "    input_msg = Input((train_data.shape[1], 1))\n",
    "    encoded = Conv1D(filters=fnum1, kernel_size=4, strides=1, padding='same', activation='tanh',kernel_initializer=initializers.random_normal(stddev=0.01), bias_initializer='zeros')(input_msg)\n",
    "    encoded = MaxPooling1D(pool_size=ps1)(encoded)\n",
    "    encoded = Conv1D(filters=fnum2, kernel_size=6, strides=1, padding='same', activation='tanh',kernel_initializer=initializers.random_normal(stddev=0.01), bias_initializer='zeros')(encoded)\n",
    "    encoder_output = MaxPooling1D(pool_size=ps2)(encoded)\n",
    "    encoder_model = Model(inputs=input_msg, outputs=encoder_output)\n",
    "\n",
    "    # 解码器，反过来\n",
    "    decoded = UpSampling1D(size=ps2)(encoder_output)##上采样过程(反卷积)\n",
    "    decoded = Conv1D(filters=fnum1, kernel_size=6, strides=1, padding='same', activation='tanh',kernel_initializer=initializers.random_normal(stddev=0.01), bias_initializer='zeros')(decoded)\n",
    "    decoded = UpSampling1D(size=ps1)(decoded)\n",
    "    decoded = Conv1D(filters=fnum2, kernel_size=4, strides=1, padding='same', activation='tanh',kernel_initializer=initializers.random_normal(stddev=0.01), bias_initializer='zeros')(decoded)\n",
    "\n",
    "    # 转成原始数据大小\n",
    "    decoded_output = Conv1D(filters=1, kernel_size=2, strides=1, padding='same', activation='tanh',kernel_initializer=initializers.random_normal(stddev=0.01), bias_initializer='zeros')(decoded)\n",
    "    autoencoder = Model(input_msg, decoded_output)\n",
    "    print(autoencoder.summary())  ## 打印网络结构\n",
    "    autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "    print(train_data.shape, input_msg.shape, decoded_output.shape, encoder_output.shape)\n",
    "    bs = int(len(train_data) / 4)  ##### 数据集较少，全参与形式，epochs一般跟batch_size成正比\n",
    "    epochs = max(int(bs / 2), 128 * 3)\n",
    "    a = autoencoder.fit(train_data, train_data, epochs=epochs, batch_size=bs, verbose=0, validation_split=0.2)## 在训练集中划分0.2作为测试集\n",
    "    print('训练集Loss列表(长度%s)%s:' % (len(a.history['loss']), a.history['loss']))\n",
    "    print('测试集Loss列表(长度%s)%s:' % (len(a.history['val_loss']), a.history['val_loss']))\n",
    "    print('\\033[1;31m{0:*^80}\\033[0m'.format('测试集损失函数情况'))\n",
    "    print(autoencoder.evaluate(test_data, test_data))  ## 观察测试集损失情况\n",
    "    # encoder_model.save('临时保存的CNN模型.hdf5')\n",
    "    return encoder_model,bs,a.history['loss'],a.history['val_loss'],autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = bulid_CNNmodel(traindata,testdata)\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###预测和作图\n",
    "def outputresult(data,model):\n",
    "    modelres = model(data,data)\n",
    "    dim_msg = modelres[0].predict(data)##此时预测是拿纯测试集预测\n",
    "    print('降维后数据维度：',dim_msg.shape)\n",
    "    dim_msg = np.reshape(dim_msg,(dim_msg.shape[0],dim_msg.shape[1]))\n",
    "    latent_feature = pd.DataFrame(dim_msg)\n",
    "    latent_feature.index = originaldata.index##read_res[2]\n",
    "    latent_feature.columns = [('feature'+str(i + 1)) for i in range(dim_msg.shape[1])]\n",
    "    latent_feature = np.round(latent_feature,6)\n",
    "    print(latent_feature)\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(modelres[2], label='训练集损失',)\n",
    "    plt.plot(modelres[3], label='测试集损失')\n",
    "    plt.xlabel('循环次数',fontsize=18)\n",
    "    plt.tick_params(labelsize=18)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.show()\n",
    "    return x_all_normalize.shape\n",
    "outputresult(x_all_normalize,bulid_BPNNmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78ddfc3686b8b7161f2836984651df038ec9a0366954334fc42499f59ad2b3c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
